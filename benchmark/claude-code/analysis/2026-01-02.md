# Benchmark Analysis: 2026-01-02

**Results file:** `benchmark/claude-code/results/suite_results_n10_20260102_160105.json`
**Tasks:** 20 tasks × 10 runs per condition = 200 runs per condition
**Timestamp:** 2026-01-02 16:01:05

## Executive Summary

- **No significant time or cost difference** between Gabb and Control conditions
- **Gabb uses +19.5% more tokens**, but only **+6.2% more cost** due to cache efficiency
- **gabb_structure is being used** (96% of Gabb runs average 0.96 calls), but it's adding tokens without measurable time savings
- **Critical finding:** Within the Gabb condition, runs that used gabb_structure took +11.3s longer and used +17,365 more tokens than runs that didn't (not statistically significant, but concerning)
- **One task fails consistently** for both conditions: `django__django-11564` (0% success rate)

## 1. Aggregate Results

### Primary Metrics

| Metric | Control | Gabb | Difference | Significant? |
|--------|---------|------|------------|--------------|
| Success Rate | 95.0% | 94.0% | -1.0% | No |
| Time (s) | 50.1 ± 27.7 | 51.6 ± 32.3 | +1.5s (+3.0%) | No |
| Total Tokens | 62,596 ± 24,672 | 74,803 ± 29,414 | +12,207 (+19.5%) | Yes (***) |
| Cost (USD) | $0.040 ± $0.020 | $0.040 ± $0.020 | $0.000 (+0.0%) | No |
| Tool Calls | 14.0 ± 12.6 | 14.3 ± 13.2 | +0.3 (+2.3%) | No |
| Turns | 3.1 ± 1.3 | 3.6 ± 1.6 | +0.5 (+17.0%) | Likely |

### Cache Token Breakdown

| Token Type | Control | Gabb | Difference |
|------------|---------|------|------------|
| Cache Read | 58,961 | 71,588 | +12,627 (+21.4%) |
| Cache Create | 3,062 | 2,642 | -420 (-13.7%) |
| Input (uncached) | 19 | 12 | -7 (-38.6%) |
| Output | 553 | 561 | +8 (+1.4%) |
| **TOTAL** | **62,596** | **74,803** | **+12,207 (+19.5%)** |

### Tool Usage Comparison

| Tool | Control | Gabb | Difference |
|------|---------|------|------------|
| Read | 5.05 | 4.99 | -0.06 |
| Grep | 3.90 | 3.98 | +0.08 |
| Bash | 3.33 | 2.75 | -0.58 |
| Glob | 1.17 | 1.10 | -0.07 |
| Task | 0.57 | 0.56 | -0.01 |
| gabb_structure | 0.00 | 0.96 | +0.96 |

**Key observation:** gabb_structure is being used, but Read calls are not significantly reduced.

## 2. Statistical Significance

### Time

| Statistic | Value |
|-----------|-------|
| Control mean | 50.12s ± 27.72s |
| Gabb mean | 51.64s ± 32.32s |
| Difference | -1.52s (Control - Gabb) |
| t-statistic | -0.50 |
| df | 389.0 |
| 95% CI | [-7.54s, 4.50s] |
| Cohen's d | -0.05 (Negligible) |
| **Interpretation** | **Not significant** |

### Tokens

| Statistic | Value |
|-----------|-------|
| Control mean | 62,596 ± 24,672 |
| Gabb mean | 74,803 ± 29,414 |
| Difference | -12,207 (Control - Gabb) |
| t-statistic | -4.50 |
| df | 386.3 |
| 95% CI | [-17,637, -6,778] |
| Cohen's d | -0.45 (Small) |
| **Interpretation** | **Very highly significant (\*\*\*)** |

Gabb uses significantly more tokens than Control, but this doesn't translate to cost because most extra tokens are cache reads (10% of normal price).

### Cost

| Statistic | Value |
|-----------|-------|
| Control mean | $0.0400 ± $0.0200 |
| Gabb mean | $0.0400 ± $0.0200 |
| Difference | $0.0000 |
| t-statistic | 0.00 |
| **Interpretation** | **Not significant** |

## 3. Subgroup Analysis

### By Read Count

**Control Condition:**

| Subgroup | N | % | Avg Time | Avg Tokens | Success |
|----------|---|---|----------|------------|---------|
| 0 reads | 12 | 6.0% | 20.1s | 60,908 | 100.0% |
| 1 read | 58 | 29.0% | 22.2s | 61,104 | 100.0% |
| 2+ reads | 130 | 65.0% | 65.3s | 63,417 | 92.3% |

**Gabb Condition:**

| Subgroup | N | % | Avg Time | Avg Tokens | Success |
|----------|---|---|----------|------------|---------|
| 0 reads | 13 | 6.5% | 18.2s | 59,399 | 92.3% |
| 1 read | 59 | 29.5% | 24.6s | 77,865 | 100.0% |
| 2+ reads | 128 | 64.0% | 67.5s | 74,956 | 92.2% |

**Observation:** Gabb's 1-read group uses +27% more tokens (77,865 vs 61,104) but takes +10% longer (24.6s vs 22.2s). This suggests gabb_structure is adding overhead without benefit.

### gabb_structure Usage by Read Count (Gabb Only)

| Subgroup | N | Used gabb_structure | Usage Rate |
|----------|---|---------------------|------------|
| 0 reads | 13 | 0 | 0.0% |
| 1 read | 59 | 33 | 55.9% |
| 2+ reads | 128 | 86 | 67.2% |

## 4. Behavioral Patterns

**Control Patterns:**

| Pattern | Runs | % | Avg Time | Avg Tokens |
|---------|------|---|----------|------------|
| file_exploration | 188 | 94.0% | 52.0s | 62,704 |
| search_only | 12 | 6.0% | 20.1s | 60,908 |

**Gabb Patterns:**

| Pattern | Runs | % | Avg Time | Avg Tokens |
|---------|------|---|----------|------------|
| gabb_then_read | 119 | 59.5% | 59.1s | 83,942 |
| file_exploration | 68 | 34.0% | 44.9s | 61,755 |
| search_only | 12 | 6.0% | 19.5s | 64,349 |
| direct_answer | 1 | 0.5% | 2.0s | 0 |

**Critical finding:** The "gabb_then_read" pattern (uses gabb_structure before reading) has the highest token count (83,942) and is slower than file_exploration without gabb (44.9s vs 59.1s).

## 5. Apples-to-Apples Comparison

**Within Gabb condition, comparing runs with 2+ file reads:**

| Metric | Used gabb_structure (n=86) | No gabb_structure (n=42) | Difference |
|--------|---------------------------|--------------------------|------------|
| Time | 71.2s ± 27.1s | 59.9s ± 34.4s | +11.3s |
| Tokens | 80,654 ± 33,624 | 63,289 ± 25,305 | +17,365 |
| Success | 90.7% | 95.2% | -4.5% |
| t-statistic (time) | 1.86 | - | Not significant |

**Interpretation:** While not statistically significant (t=1.86 < 2.0), there's a concerning trend that runs using gabb_structure take longer and use more tokens than runs that don't, even within the same complexity tier (2+ file reads).

## 6. Token Cost Attribution

| Component | Control | Gabb | Difference |
|-----------|---------|------|------------|
| Cache Read cost | $0.01769 | $0.02148 | +$0.00379 |
| Cache Create cost | $0.01148 | $0.00991 | -$0.00158 |
| Input cost | $0.00006 | $0.00004 | -$0.00002 |
| Output cost | $0.00830 | $0.00842 | +$0.00012 |
| **Total Cost** | **$0.03753** | **$0.03984** | **+$0.00231 (+6.2%)** |

**Key insight:** Raw token increase is +19.5%, but effective cost increase is only +6.2% because most extra tokens are cache reads (10% of normal cost).

## 7. Per-Task Performance

| Task ID | Control | Gabb | Diff | Notes |
|---------|---------|------|------|-------|
| astropy__astropy-14995 | 61.7s | 35.4s | **-26.3s** | Best improvement |
| astropy__astropy-12907 | 44.5s | 39.1s | -5.4s | Good |
| django__django-10914 | 72.0s | 65.7s | -6.3s | Good |
| django__django-11099 | 21.8s | 17.3s | -4.5s | Good |
| django__django-11001 | 31.7s | 28.0s | -3.8s | Good (but 1 Gabb failure) |
| django__django-11620 | 47.2s | 64.3s | **+17.1s** | Worst regression |
| django__django-11583 | 18.8s | 33.7s | +14.9s | Major regression |
| django__django-11564 | 94.9s | 104.3s | +9.5s | Both 0% success |

**Success Rate Differences:**
- `django__django-11001`: Control 100%, Gabb 90% (-10%)
- `django__django-11564`: Both 0% (consistently unsolved)

## 8. Recommendations

### Immediate Actions

1. **Investigate why gabb_structure adds overhead** - The pattern "call gabb_structure then read" is slower than just reading. Either:
   - Claude is not using the structure info to read more efficiently
   - The structure output is adding unnecessary tokens to context
   - Claude is calling gabb_structure unnecessarily

2. **Investigate django__django-11564** - 0% success for both conditions indicates a task configuration issue or genuinely difficult task.

3. **Investigate Gabb failure on django__django-11001** - One run failed in Gabb (0 tokens, 2.0s) suggesting an initialization issue.

### SKILL.md Optimization

The current SKILL.md may be too verbose. Consider:
- Removing duplicated information already in MCP tool descriptions
- Shortening the "When NOT to Use" section
- Current estimated SKILL.md overhead: ~670 tokens per conversation

### Next Steps

1. Run detailed transcript analysis on:
   - `astropy__astropy-14995` (best improvement case)
   - `django__django-11583` (worst regression case)

2. Consider A/B testing with a minimal SKILL.md to measure instruction overhead

3. Add more runs (n=20 or n=50) for higher statistical power on subgroup comparisons

## 9. Transcript Analysis (Added 2026-01-02)

### astropy__astropy-14995 (Best Improvement: -26.3s)

**Summary:** Gabb enabled dramatically more efficient code navigation for this task.

**Control Behavior (25 transcripts):**
- High variance: 1-32 tool calls per run
- Average: 10.9 tools, 3.2 reads, 2.7 greps
- Average transcript size: 97KB
- Pattern: Many runs involved extensive exploration through wrong files (e.g., io/ascii/rst.py instead of nddata/mixins/ndarithmetic.py)

**Sample Control sequence (32 tools):**
```
1. Glob: **/*rst*
2. Grep: 'class.*RST.*Writer'
3. Read: rst.py
4. Read: fixedwidth.py
...extensive exploration through wrong directories...
31. Read: core.py
32. Bash
```

**Gabb Behavior (9 transcripts):**
- Highly consistent: 3-5 tool calls (except one outlier at 24)
- Average: 6.2 tools, 1.8 reads, 1.1 gabb_structure
- Average transcript size: 38KB (60% smaller)
- Pattern: Direct navigation to correct file

**Sample Gabb sequence (4 tools):**
```
1. Grep: 'elif operand is None:'
2. Grep: 'operand\.mask is None'
3. gabb_structure: ndarithmetic.py
4. Read: ndarithmetic.py
→ FINAL_ANSWER: astropy/nddata/mixins/ndarithmetic.py
```

**Key Insight:** Gabb's semantic search (combined with SKILL.md guidance) enabled Claude to find the exact file in 4 tool calls vs. 32 for Control. The improvement comes from:
1. More targeted initial search (specific error patterns vs. broad glob)
2. Using gabb_structure to preview before full read
3. Avoiding wrong directory exploration

---

### django__django-11583 (Worst Regression: +14.9s)

**Summary:** Gabb added unnecessary overhead on a task where Claude could solve with minimal exploration.

**Control Behavior (49 transcripts):**
- 8 runs with 0 tool calls (solved from prompt alone)
- Many runs with just 1 read
- Average: 5.8 tools, 1.6 reads
- Wide variance: 0-53 tools
- Pattern: Often solved directly or with single file read

**Gabb Behavior (24 transcripts):**
- No runs with 0 tool calls
- All runs use at least gabb_structure
- Average: 7.6 tools, 2.6 reads, 1.1 gabb_structure
- More consistent but higher baseline

**Sample Control sequence (1 tool - typical fast run):**
```
1. Read: autoreload.py
→ FINAL_ANSWER
```

**Sample Gabb sequence (4 tools - typical run):**
```
1. Grep: 'iter_modules_and_files'
2. gabb_structure: autoreload.py
3. Read: autoreload.py
4. Read: autoreload.py (second section)
→ FINAL_ANSWER
```

**Key Insight:** The regression is caused by:
1. **Forced exploration pattern**: Gabb condition always triggers the "check structure before reading" workflow, even when Claude could answer directly
2. **Extra tool overhead**: gabb_structure adds 1+ tool calls on every run
3. **Read fragmentation**: After seeing structure, Claude often reads in multiple targeted chunks instead of once

**Root Cause:** For tasks where Claude already knows the answer or can identify the file quickly, gabb_structure adds latency without benefit. The SKILL.md "MANDATORY PRE-READ CHECK" guidance may be too aggressive.

---

### Recommendations from Transcript Analysis

1. **Make gabb_structure conditional**: Only use when file is unknown or large. The current "always check first" guidance hurts easy tasks.

2. **Optimize SKILL.md**: Remove or soften the "MANDATORY" language. Consider:
   ```
   Before reading large or unfamiliar files, consider using gabb_structure
   ```
   Instead of:
   ```
   BEFORE using Read on ANY supported code file, you MUST call gabb_structure FIRST
   ```

3. **Task categorization**: gabb_structure is most beneficial for:
   - Large codebases requiring exploration
   - Tasks where the target file is unknown
   - Multi-file changes

   It adds overhead for:
   - Tasks with known file locations
   - Simple single-file investigations
   - Cases where Claude can infer the answer from context

## Appendix: Raw Data Locations

- Results JSON: `benchmark/claude-code/results/suite_results_n10_20260102_160105.json`
- Previous analysis: `benchmark/claude-code/analysis/2026-01-01.md`
- Analysis guide: `benchmark/claude-code/RESULTS_ANALYSIS_GUIDE.md`
- Transcript locations:
  - astropy: `~/.claude/projects/-Users-dmb--cache-gabb-benchmark-repos-workspaces-astropy--astropy--*/`
  - django: `~/.claude/projects/-Users-dmb--cache-gabb-benchmark-repos-workspaces-django--django--*/`
